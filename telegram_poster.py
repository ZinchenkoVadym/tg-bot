import asyncio
import time
import schedule
import requests
from bs4 import BeautifulSoup  # –í–ò–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∏–π —ñ–º–ø–æ—Ä—Ç BeautifulSoup
from urllib.parse import urljoin
import feedparser
from telegram import Bot
from telegram.error import TelegramError
import re
import os
import random
from thefuzz import fuzz
import pytz
from datetime import datetime

# --- –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–Ø ---
BOT_TOKEN = os.environ.get('BOT_TOKEN')
CHANNEL_ID = os.environ.get('CHANNEL_ID')

# --- –ù–ê–õ–ê–®–¢–£–í–ê–ù–ù–Ø –î–ñ–ï–†–ï–õ ---
SOURCES = [
    {"name": "–Ü–¢ (DOU.ua)", "rss_url": "https://dou.ua/lenta/articles/feed/", "base_url": "https://dou.ua/",
     "content_selectors": ["div.article-body", "div.b-typo"]},
    {"name": "–ù–æ–≤–∏–Ω–∏ (–£–∫—Ä. –ü—Ä–∞–≤–¥–∞)", "rss_url": "https://www.pravda.com.ua/rss/",
     "base_url": "https://www.pravda.com.ua", "content_selectors": ["div.post_content"]},
    {"name": "–Ü–¢ (AIN.UA)", "rss_url": "https://ain.ua/feed/", "base_url": "https://ain.ua/",
     "content_selectors": ["div.post-content"]},
    {"name": "–í—ñ–π–Ω–∞ (–£–ù–Ü–ê–ù)", "rss_url": "https://rss.unian.ua/war.rss", "base_url": "https://www.unian.ua/",
     "content_selectors": ["div.article-text"]},
    {"name": "–Ü–¢ (ITC.ua)", "rss_url": "https://itc.ua/ua/feed/", "base_url": "https://itc.ua/ua/",
     "content_selectors": ["div.entry-content"]}
]
AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
STATE_FILE = 'bot_state.txt'
GLOBAL_POSTED_TITLES_FILE = 'global_posted_titles.txt'
MAX_TITLES_TO_KEEP = 100
SIMILARITY_THRESHOLD = 85
KYIV_TZ = pytz.timezone('Europe/Kiev')


# --- –§—É–Ω–∫—Ü—ñ—ó –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ –≥–ª–æ–±–∞–ª—å–Ω–æ—é –ø–∞–º'—è—Ç—Ç—é ---
def get_recent_titles():
    try:
        with open(GLOBAL_POSTED_TITLES_FILE, 'r', encoding='utf-8') as f:
            return [line.strip() for line in f]
    except FileNotFoundError:
        return []


def add_recent_title(title):
    titles = get_recent_titles()
    titles.append(title)
    with open(GLOBAL_POSTED_TITLES_FILE, 'w', encoding='utf-8') as f:
        f.write('\n'.join(titles[-MAX_TITLES_TO_KEEP:]))


def is_duplicate_title(new_title, recent_titles):
    for old_title in recent_titles:
        similarity = fuzz.ratio(new_title.lower(), old_title.lower())
        if similarity > SIMILARITY_THRESHOLD:
            print(f"–ó–Ω–∞–π–¥–µ–Ω–æ –¥—É–±–ª—ñ–∫–∞—Ç: '{new_title}' —Å—Ö–æ–∂–∏–π –Ω–∞ '{old_title}' ({similarity}%)")
            return True
    return False


# --- –§—É–Ω–∫—Ü—ñ—ó –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ –¥–∂–µ—Ä–µ–ª–∞–º–∏ ---
def get_next_source_index():
    try:
        with open(STATE_FILE, 'r') as f:
            last_index = int(f.read().strip())
            return (last_index + 1) % len(SOURCES)
    except (FileNotFoundError, ValueError):
        return 0


def save_current_source_index(index):
    with open(STATE_FILE, 'w') as f:
        f.write(str(index))


def get_fallback_image():
    return "https://picsum.photos/1280/720"


def get_article_details(article_url, content_selectors):
    try:
        headers = {'User-Agent': AGENT}
        response = requests.get(article_url, headers=headers, timeout=15)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        image_tag = soup.find('meta', property='og:image')
        image_url = image_tag['content'] if image_tag else None
        article_body = None
        for selector in content_selectors:
            article_body = soup.select_one(selector)
            if article_body:
                break
        if not article_body: return None, None
        for tag in article_body.find_all(['pre', 'code', 'script', 'style', 'aside']):
            tag.decompose()
        full_text = ' '.join(p.get_text(strip=True) for p in article_body.find_all('p'))
        sentences = re.split(r'(?<=[.!?])\s+', full_text)
        summary = ' '.join(sentences[:3]).strip()
        return image_url, summary if summary else None
    except Exception as e:
        print(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –¥–µ—Ç–∞–ª—ñ —Å—Ç–∞—Ç—Ç—ñ {article_url}: {e}")
        return None, None


async def send_post_to_telegram(title, link, source_config):
    image_url, summary = get_article_details(link, source_config['content_selectors'])
    if not summary:
        print(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –æ–ø–∏—Å –¥–ª—è —Å—Ç–∞—Ç—Ç—ñ: {title}. –ü—Ä–æ–ø—É—Å–∫–∞—é.")
        return False
    if not image_url:
        print("–†–µ–∞–ª—å–Ω–µ —Ñ–æ—Ç–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –ë–µ—Ä—É –≤–∏–ø–∞–¥–∫–æ–≤–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è...")
        image_url = get_fallback_image()
    bot = Bot(BOT_TOKEN)
    caption = f"*{title}*\n\n{summary}"
    if len(caption) > 1024: caption = caption[:1020] + "..."
    try:
        if image_url:
            await bot.send_photo(chat_id=CHANNEL_ID, photo=image_url, caption=caption, parse_mode='Markdown')
        else:
            await bot.send_message(chat_id=CHANNEL_ID, text=caption, parse_mode='Markdown')
        print(f"‚úÖ –ü–æ—Å—Ç '{title}' —É—Å–ø—ñ—à–Ω–æ –≤—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–æ!")
        add_recent_title(title)
        return True
    except TelegramError as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ Telegram: {e}")
        return False


# --- –û—Å–Ω–æ–≤–Ω–∞ –ª–æ–≥—ñ–∫–∞ –∑ –Ω–æ–≤–æ—é –ø–µ—Ä–µ–≤—ñ—Ä–∫–æ—é ---
async def post_news_from_source(source_config):
    """–ó–Ω–∞—Ö–æ–¥–∏—Ç—å —É–Ω—ñ–∫–∞–ª—å–Ω—É —Å—Ç–∞—Ç—Ç—é —ñ –ø–æ–≤–µ—Ä—Ç–∞—î True —É —Ä–∞–∑—ñ —É—Å–ø—ñ—à–Ω–æ–≥–æ –ø–æ—Å—Ç–∏–Ω–≥—É."""
    print(f"–ü–µ—Ä–µ–≤—ñ—Ä—è—é –¥–∂–µ—Ä–µ–ª–æ: {source_config['name']} - {source_config['rss_url']}")
    try:
        headers = {'User-Agent': AGENT}
        response = requests.get(source_config['rss_url'], headers=headers, timeout=15)
        response.raise_for_status()
        feed = feedparser.parse(response.content)
        if not feed.entries:
            print("–°—Ç—Ä—ñ—á–∫–∞ –Ω–æ–≤–∏–Ω –ø–æ—Ä–æ–∂–Ω—è –∞–±–æ –Ω–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏.")
            return False

        recent_titles = get_recent_titles()

        for entry in feed.entries:
            title = entry.title.strip()

            if not is_duplicate_title(title, recent_titles):
                print(f"–ó–Ω–∞–π–¥–µ–Ω–æ —É–Ω—ñ–∫–∞–ª—å–Ω—É —Å—Ç–∞—Ç—Ç—é: {title}")
                link = urljoin(source_config['base_url'], entry.link)
                if await send_post_to_telegram(title, link, source_config):
                    return True  # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ True, —è–∫—â–æ –ø–æ—Å—Ç –≤—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–æ

        print("–ù–æ–≤–∏—Ö —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö —Å—Ç–∞—Ç–µ–π —É —Ü—å–æ–º—É –¥–∂–µ—Ä–µ–ª—ñ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return False
    except Exception as e:
        print(f"–°—Ç–∞–ª–∞—Å—è –∑–∞–≥–∞–ª—å–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ –¥–∂–µ—Ä–µ–ª–∞ {source_config['name']}: {e}")
        return False


async def main_task():
    """
    –ù–û–í–ê –õ–û–ì–Ü–ö–ê: –ü–µ—Ä–µ–±–∏—Ä–∞—î –¥–∂–µ—Ä–µ–ª–∞ –ø–æ –∫–æ–ª—É, –¥–æ–∫–∏ –Ω–µ –æ–ø—É–±–ª—ñ–∫—É—î –ø–æ—Å—Ç.
    """
    start_index = get_next_source_index()
    post_sent = False

    # –ü–µ—Ä–µ–±–∏—Ä–∞—î–º–æ –≤—Å—ñ –¥–∂–µ—Ä–µ–ª–∞, –ø–æ—á–∏–Ω–∞—é—á–∏ –∑ –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ –∑–∞ –ø–ª–∞–Ω–æ–º
    for i in range(len(SOURCES)):
        current_index = (start_index + i) % len(SOURCES)
        source_config = SOURCES[current_index]

        if await post_news_from_source(source_config):
            print(f"‚úÖ –ü–æ—Å—Ç —É—Å–ø—ñ—à–Ω–æ –≤—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–æ –∑ –¥–∂–µ—Ä–µ–ª–∞: {source_config['name']}")
            save_current_source_index(current_index)  # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —ñ–Ω–¥–µ–∫—Å —É—Å–ø—ñ—à–Ω–æ–≥–æ –¥–∂–µ—Ä–µ–ª–∞
            post_sent = True
            break  # –í–∏—Ö–æ–¥–∏–º–æ –∑ —Ü–∏–∫–ª—É, –æ—Å–∫—ñ–ª—å–∫–∏ –ø–æ—Å—Ç –≤–∂–µ –≤—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–æ

    if not post_sent:
        print("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –≤—ñ–¥–ø—Ä–∞–≤–∏—Ç–∏ –ø–æ—Å—Ç –∑ –∂–æ–¥–Ω–æ–≥–æ –¥–∂–µ—Ä–µ–ª–∞ –ø—ñ—Å–ª—è –ø–µ—Ä–µ–±–æ—Ä—É –≤—Å—ñ—Ö.")


def job():
    current_hour = datetime.now(KYIV_TZ).hour
    if not (current_hour >= 8 or current_hour < 1):
        print(f"–ó–∞—Ä–∞–∑ {current_hour}:00 (–ö–∏—ó–≤). –ü–æ—Å—Ç–∏–Ω–≥ –ø—Ä–∏–∑—É–ø–∏–Ω–µ–Ω–æ –¥–æ 8 —Ä–∞–Ω–∫—É.")
        return

    print(f"\n--- {datetime.now(KYIV_TZ).strftime('%Y-%m-%d %H:%M:%S')} ---")
    asyncio.run(main_task())


# --- –ü–õ–ê–ù–£–í–ê–õ–¨–ù–ò–ö ---
# –ó–∞–ø—É—Å–∫–∞—î–º–æ –∑–∞–≤–¥–∞–Ω–Ω—è –∫–æ–∂–Ω—É –≥–æ–¥–∏–Ω—É.
schedule.every(1).hours.do(job)

print("üöÄ –†–æ–∑—É–º–Ω–∏–π –±–æ—Ç-–∞–≥—Ä–µ–≥–∞—Ç–æ—Ä –∑–∞–ø—É—â–µ–Ω–∏–π.")
print("–ü–µ—Ä—à–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –≤—ñ–¥–±—É–¥–µ—Ç—å—Å—è –Ω–µ–≥–∞–π–Ω–æ, —è–∫—â–æ —á–∞—Å –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–π (08:00 - 01:00).")
job()  # –ü–µ—Ä—à–∏–π –∑–∞–ø—É—Å–∫ –æ–¥—Ä–∞–∑—É

while True:
    schedule.run_pending()
    time.sleep(1)
